{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOWzVm4/0+oCBqPEZlXlZin"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"oDw9dv25x-5z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MATLAB code"],"metadata":{"id":"yqrOfB-Ox-0h"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQddPVyYxt_m"},"outputs":[],"source":["%% example: effects of sleep and study hours on exam scores\n","\n","%%% create the data\n","exam_scores = [];\n","for ei=0:4\n","    exam_scores = [ exam_scores 60*ones(1,6)+linspace(-1,5,6)*ei ];\n","end\n","\n","exam_scores = exam_scores'; % force column vector\n","hours_studied = repmat(linspace(2,8,6),1,5)';\n","ave_sleep_hrs = linspace(6,10,30)';\n","\n","%% plot the data\n","\n","% stratify by hours studied\n","figure(1), clf, hold on\n","\n","% fewer than 4 hours studied\n","plotidx = hours_studied<4.1;\n","plot(ave_sleep_hrs(plotidx),exam_scores(plotidx),'ko','markerfacecolor','k','markersize',10)\n","\n","% 5-6 hours studied\n","plotidx = hours_studied>4.9 & hours_studied<6.1;\n","plot(ave_sleep_hrs(plotidx),exam_scores(plotidx),'rs','markerfacecolor','r','markersize',10)\n","\n","% more than 6 hours\n","plotidx = hours_studied>6;\n","plot(ave_sleep_hrs(plotidx),exam_scores(plotidx),'b^','markerfacecolor','b','markersize',10)\n","\n","xlabel('Hours of sleep'), ylabel('Exam score')\n","legend({'<4 hours studied';'5-6 hours studied';'>7 hours studied'})\n","\n","%% compute the multiple regression\n","\n","% first create the design matrix\n","desmat = [ ones(30,1) ave_sleep_hrs hours_studied ave_sleep_hrs.*hours_studied ];\n","\n","[beta,b_CI,resids,rint,stats] = regress(exam_scores,desmat);\n","\n","% stats vector is R2, F, p-val, error variance\n","stats\n","\n","%% inspect the residuals\n","\n","figure(2), clf\n","plot(exam_scores,resids,'ks','markerfacecolor','k')\n","xlabel('Exam scores')\n","ylabel('Model residuals')\n","\n","%% using fitlm\n","\n","% with explicit intercept\n","lm1 = fitlm(desmat,exam_scores,'VarNames',{'Intercept','Ave sleep','Study hours','Interaction','Exam scores'})\n","\n","% without intercept\n","% lm2 = fitlm(desmat(:,2:end),exam_scores,'VarNames',{'Ave sleep','Studyhours','Interaction','Exam scores'});\n","\n","% without interaction term\n","lm3 = fitlm(desmat(:,2:3),exam_scores,'VarNames',{'Ave sleep','Study hours','Exam scores'});\n","\n","% specify the model\n","lm4 = fitlm(desmat(:,2:3),exam_scores,'exam ~ sleep*study',...\n","    'VarNames',{'sleep','study','exam'});\n","\n","%% correlation of IVs\n","\n","corr(desmat(:,2:end))\n","\n","%% done.\n"]},{"cell_type":"code","source":[],"metadata":{"id":"37OjyYaXSmHd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Python code to translate into R"],"metadata":{"id":"paYK9ZHnSmEV"}},{"cell_type":"code","source":["# import libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","\n","# In[ ]:\n","\n","\n","## create data for the bar plot\n","\n","# data sizes\n","m = 30 # rows\n","n =  6 # columns\n","\n","# generate data\n","data = np.zeros((m,n))\n","\n","for i in range(n):\n","    data[:,i] = 30*np.random.randn(m) * (2*i/(n-1)-1)**2 + (i+1)**2\n","\n","\n","# In[ ]:\n","\n","\n","# show the bars!\n","\n","fig,ax = plt.subplots(1,3,figsize=(8,2))\n","\n","# 'naked' bars\n","ax[0].bar(range(n),np.mean(data,axis=0))\n","ax[0].set_title('Bar plot')\n","\n","# just the error bars\n","ax[1].errorbar(range(n),np.mean(data,axis=0),np.std(data,axis=0,ddof=1),marker='s',linestyle='')\n","ax[1].set_title('Errorbar plot')\n","\n","# both\n","ax[2].bar(range(n),np.mean(data,axis=0))\n","ax[2].errorbar(range(n),np.mean(data,axis=0),np.std(data,axis=0,ddof=1),marker='.',linestyle='',color='k')\n","ax[2].set_title('Error+bar plot')\n","\n","plt.show()\n","\n","\n","# In[ ]:\n","\n","\n","## manually specify x-axis coordinates\n","\n","xcrossings = [ 1, 2, 4, 5, 6, 9 ]\n","\n","plt.bar(xcrossings,np.mean(data,axis=0))\n","plt.errorbar(xcrossings,np.mean(data,axis=0),np.std(data,axis=0,ddof=1),marker='.',linestyle='',color='k')\n","plt.title('Bar+error plot')\n","\n","plt.show()\n","\n","\n","# In[ ]:\n","\n","\n","## note about bars from matrices\n","\n","# data are groups (rows) X property (columns)\n","m = [ [2,5,4,3], [1,1,8,6] ]\n","\n","fig,ax = plt.subplots(nrows=2,ncols=2,figsize=(8,8))\n","\n","# conceptualizing the data as <row> groups of <columns>\n","ax[0,0].imshow(m)\n","\n","# using pandas dataframe\n","df = pd.DataFrame(m,columns=['prop 0','prop 1','prop 2','prop 3'])\n","df.plot(ax=ax[1,0],kind='bar')\n","ax[1,0].set_title('Grouping by rows')\n","\n","\n","# now other orientation (property X group)\n","ax[0,1].imshow(np.array(m).T)\n","df.T.plot(ax=ax[1,1],kind='bar')\n","ax[1,1].set_title('Grouping by columns')\n","\n","plt.show()"],"metadata":{"id":"RYmSRvw3SoXv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AyB8XB1_SmBw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PyTorch to TensorFlow"],"metadata":{"id":"u9SaDYOkcQaj"}},{"cell_type":"code","source":["# import libraries\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader,TensorDataset\n","from sklearn.model_selection import train_test_split\n","\n","# for getting summary info on models\n","from torchsummary import summary\n","\n","import matplotlib.pyplot as plt\n","from IPython import display\n","display.set_matplotlib_formats('svg')\n","\n","\"\"\"# Import and process the data\"\"\"\n","\n","# import dataset (comes with colab!)\n","data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n","\n","# extract labels (number IDs) and remove from data\n","labels = data[:,0]\n","data   = data[:,1:]\n","\n","# normalize the data to a range of [0 1]\n","dataNorm = data / np.max(data)\n","\n","# NEW: reshape to 2D!\n","dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28)\n","\n","dataNorm.shape\n","\n","\"\"\"# Create train/test groups using DataLoader\"\"\"\n","\n","# Step 1: convert to tensor\n","dataT   = torch.tensor( dataNorm ).float()\n","labelsT = torch.tensor( labels ).long()\n","\n","# Step 2: use scikitlearn to split the data\n","train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n","\n","\n","# Step 3: convert into PyTorch Datasets\n","train_data = TensorDataset(train_data,train_labels)\n","test_data  = TensorDataset(test_data,test_labels)\n","\n","# Step 4: translate into dataloader objects\n","batchsize    = 32\n","train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n","test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n","\n","# check size (should be images X channels X width X height)\n","train_loader.dataset.tensors[0].shape\n","\n","\"\"\"# Create the DL model\"\"\"\n","\n","# create a class for the model\n","def createTheMNISTNet(printtoggle=False):\n","\n","  class mnistNet(nn.Module):\n","    def __init__(self,printtoggle):\n","      super().__init__()\n","\n","      ### convolution layers\n","      self.conv1 = nn.Conv2d( 1,10,kernel_size=5,stride=1,padding=1)\n","      # size: np.floor( (28+2*1-5)/1 )+1 = 26/2 = 13 (/2 b/c maxpool)\n","\n","      self.conv2 = nn.Conv2d(10,20,kernel_size=5,stride=1,padding=1)\n","      # size: np.floor( (13+2*1-5)/1 )+1 = 11/2 = 5 (/2 b/c maxpool)\n","\n","      # compute the number of units in FClayer (number of outputs of conv2)\n","      expectSize = np.floor( (5+2*0-1)/1 ) + 1 # fc1 layer has no padding or kernel, so set to 0/1\n","      expectSize = 20*int(expectSize**2)\n","      \n","      ### fully-connected layer\n","      self.fc1 = nn.Linear(expectSize,50)\n","\n","      ### output layer\n","      self.out = nn.Linear(50,10)\n","\n","      # toggle for printing out tensor sizes during forward prop\n","      self.print = printtoggle\n","\n","    # forward pass\n","    def forward(self,x):\n","      \n","      print(f'Input: {x.shape}') if self.print else None\n","\n","      # convolution -> maxpool -> relu\n","      x = F.relu(F.max_pool2d(self.conv1(x),2))\n","      print(f'Layer conv1/pool1: {x.shape}') if self.print else None\n","\n","      # and again: convolution -> maxpool -> relu\n","      x = F.relu(F.max_pool2d(self.conv2(x),2))\n","      print(f'Layer conv2/pool2: {x.shape}') if self.print else None\n","\n","      # reshape for linear layer\n","      nUnits = x.shape.numel()/x.shape[0]\n","      x = x.view(-1,int(nUnits))\n","      if self.print: print(f'Vectorize: {x.shape}')\n","      \n","      # linear layers\n","      x = F.relu(self.fc1(x))\n","      if self.print: print(f'Layer fc1: {x.shape}')\n","      x = self.out(x)\n","      if self.print: print(f'Layer out: {x.shape}')\n","\n","      return x\n","  \n","  # create the model instance\n","  net = mnistNet(printtoggle)\n","  \n","  # loss function\n","  lossfun = nn.CrossEntropyLoss()\n","\n","  # optimizer\n","  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n","\n","  return net,lossfun,optimizer\n","\n","# test the model with one batch\n","net,lossfun,optimizer = createTheMNISTNet(True)\n","\n","X,y = next(iter(train_loader))\n","yHat = net(X)\n","\n","# check sizes of model outputs and target variable\n","print(' ')\n","print(yHat.shape)\n","print(y.shape)\n","\n","# now let's compute the loss\n","loss = lossfun(yHat,y)\n","print(' ')\n","print('Loss:')\n","print(loss)\n","\n","# count the total number of parameters in the model\n","summary(net,(1,28,28))\n","\n","\"\"\"# Create a function that trains the model\"\"\"\n","\n","# a function that trains the model\n","\n","def function2trainTheModel():\n","\n","  # number of epochs\n","  numepochs = 2 # note: 2 epochs is a bit small, but saves time for this demo\n","  \n","  # create a new model\n","  net,lossfun,optimizer = createTheMNISTNet()\n","\n","  # initialize losses\n","  losses    = torch.zeros(numepochs)\n","  trainAcc  = []\n","  testAcc   = []\n","\n","\n","  # loop over epochs\n","  for epochi in range(numepochs):\n","\n","    # loop over training data batches\n","    net.train()\n","    batchAcc  = []\n","    batchLoss = []\n","    for X,y in train_loader:\n","\n","      # forward pass and loss\n","      yHat = net(X)\n","      loss = lossfun(yHat,y)\n","\n","      # backprop\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # loss from this batch\n","      batchLoss.append(loss.item())\n","\n","      # compute accuracy\n","      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n","      matchesNumeric = matches.float()             # convert to numbers (0/1)\n","      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n","      batchAcc.append( accuracyPct )               # add to list of accuracies\n","    # end of batch loop...\n","\n","    # now that we've trained through the batches, get their average training accuracy\n","    trainAcc.append( np.mean(batchAcc) )\n","\n","    # and get average losses across the batches\n","    losses[epochi] = np.mean(batchLoss)\n","\n","    # test accuracy\n","    net.eval()\n","    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n","    with torch.no_grad(): # deactivates autograd\n","      yHat = net(X)\n","      \n","    # compare the following really long line of code to the training accuracy lines\n","    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n","\n","  # end epochs\n","\n","  # function output\n","  return trainAcc,testAcc,losses,net\n","\n","\"\"\"# Run the model and show the results!\"\"\"\n","\n","trainAcc,testAcc,losses,net = function2trainTheModel()\n","\n","fig,ax = plt.subplots(1,2,figsize=(16,5))\n","\n","ax[0].plot(losses,'s-')\n","ax[0].set_xlabel('Epochs')\n","ax[0].set_ylabel('Loss')\n","ax[0].set_title('Model loss')\n","\n","ax[1].plot(trainAcc,'s-',label='Train')\n","ax[1].plot(testAcc,'o-',label='Test')\n","ax[1].set_xlabel('Epochs')\n","ax[1].set_ylabel('Accuracy (%)')\n","ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n","ax[1].legend()\n","\n","plt.show()\n","\n"],"metadata":{"id":"NGgp1SYXcQXt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YegvKjQlcjHe"},"execution_count":null,"outputs":[]}]}